Continious integration / Continious delivery - это про получение предсказуемых, воспроизводимых, регулярных результатов

#1

CI - добавлять разработку в ветку как можно чаще, мелкими порциями (атомарные коммиты) при этом
автоматизированно контролируя их качество (Прочитать про экстремальное программирование)
Суть - понять что система находится в потенциально сломанном состоянии как можно раньше (система запускает автототесты, линтеры)
    Позволяет понять что основная ветка находится в работоспособном состоянии

CD - когда продукт попадает на сервер. Эффективность определяется временем между тем как обновление попало на основную ветку,
    и тем, когда продукт увидел конечный пользователь. Этот подход позволяет итерироваться быстее. Чем меньше итерация, тем меньше нужно резолвить конфликтов.

Incremental rollout - когда большая компания (напр Facebook) тестирует фичи на клиентах путем выкативания и тестирования
    с увеличением количества пользователей -  0.1% - 1% - 10% - 100% Если успешная фича то количество пользователей увеличивают


#2 

Существует хранилище и координатор а так же конфигурационный файл. Суть - происходит событие в хранилище (github, gitlab), и у нас 
есть инструкции, которые описывают действия. Например -запустить линтер или тестирование. Бывает интегрированные решения и сторонние (jenkins). .gitlab-ci.yml .githubworkflow - файлы конфигурации. 

Файл конфигурации делится на более маленькие с зависимостями - jobs

Runner - выполняет рабочие задачи, может выполнять несколько. Периодически опрашивает координатора для получения работ. Когда он ее получил и выполнил, отправляет результат - успешно или нет. 
Job - может сгенерировать набор файлов - артефакты. В них можно обращаться по API для выполнения доп функционала.
yml - язык конфигурации для выполнения программ - описывает что делать и планирует jobs

Процесс: Происходит событие, вручную запускаем, по расписанию в хранилище -> координатор создает jobs с переменными окружения и передает Runner -> Он выполняет инструкции -> вынимает репозиторий и работает с ним -> передает результат обратно координатору 

!!!!!! Важное - когда pipline запускается конфигурации не меняются для соблюдения идемпотентности. Если были произведены изменения, то нужно перезапустить pipline

#3

Определения названий.

Pipline - все с чем мы работаем в CI. Так как все протекает с одной точки в другую. Он состоит из jobs

Job - одна задача которая решает атомарную смысловую еденицу. Например запустить - eslint, prettier, webpack сборку, запустить tests или отобразить диаграмму результатами. Важно разбивать на смысловые еденицы. (Набор программ похож на открытую консоль, в которой просто вводятся программы и выполняются).

Зависимости между jobs - указыают, что одна не должна выполняться, пока не выполнится другая и тд. Могут быть двух типов:
- Зависимости реальной необходимости

Артефакты - результаты работы jobs. Например статистика, которую можно использовать для визуализации прохождения тестов

Runner - "железка" которая выполняет jobs. Например gitlab runner на удаленном сервере

Stage - gitlab определение. Способ группировки jobs, в каком порядке их выполнять. Линейная структура пошагового выполнения задач lint -> build -> test -> deploy

Scripts - сценарий того как будет выполняться job

Steps - шаги внутри job, которые нужно выполнять

#4

Не стесняться разбивать Pipline на достаточно мелкие jobs. Это поможет в случае если упадет проверка быстро найти проблему.
package-lock.json - предназначен для воспроизводимости установки. Сохраняет необходимые версии.
При создании job учитывать версию Node чтобы получать предсказуемость работы
Для установки пакетов использовать npm ci или yarn --frozen-lockfile
yarn --frozen-lockfile позволяет в случае несоответствия версий показать ошибку
yarn.lock есть функционал который позволяет автоматически резолвить конфликты которые могут возникать
Для отслеживания результата есть код возврата. 0 - говорит о том что все произошло успешно, любой другой код говорит о проблеме. Коды могут быть как положительными так и отрицательными, особой стандартизации кодов которые возвращаются нет. Единственное соглашение - 0 значит что все хорошо

#5 

12 факторные приложения.
Состояние приложения не должно меняться от места где оно расположено - другими словами в коде не должно быть настроек (например: порт, домен, путь к БД) Код который тестируется и запускается должен быть идентичен. Такая информация должна быть указана в переменных окружения. Результат взаимодействия приложения и переменных сред -> build.
Файл .env не виден в консоли, с ним работает нодовская программа dotenv. Время жизни переменной ограничено временем сессии.

I. Кодовая база
Одна кодовая база, отслеживаемая в системе контроля версий, – множество развёртываний

II. Зависимости
Явно объявляйте и изолируйте зависимости

III. Конфигурация
Сохраняйте конфигурацию в среде выполнения

IV. Сторонние службы (Backing Services)
Считайте сторонние службы (backing services) подключаемыми ресурсами

V. Сборка, релиз, выполнение
Строго разделяйте стадии сборки и выполнения

VI. Процессы
Запускайте приложение как один или несколько процессов не сохраняющих внутреннее состояние (stateless)

VII. Привязка портов (Port binding)
Экспортируйте сервисы через привязку портов

VIII. Параллелизм
Масштабируйте приложение с помощью процессов

IX. Утилизируемость (Disposability)
Максимизируйте надёжность с помощью быстрого запуска и корректного завершения работы

X. Паритет разработки/работы приложения
Держите окружения разработки, промежуточного развёртывания (staging) и рабочего развёртывания (production) максимально похожими

XI. Журналирование (Logs)
Рассматривайте журнал как поток событий

XII. Задачи администрирования
Выполняйте задачи администрирования/управления с помощью разовых процессов

#6

Переменные окружения 12 факторов. Чаще всего конфигурации хранятся в переменных окружения. Параметры чаще всего записываются в декларативном виде, хотя jobs это пошаговые инструкции. Существуют Protected переменные окружения, которые сопротивляются тому чтобы их выводили в логи и тд.
В переменных окружения чаще всего хранится - куда деплоить, как деплоить.
Есть два источника переменных окружения - 1 - файл конфигурации, переменные в этом файле доступны всем. Будут теми переменными которые будут нужны для сборки проекта
2 файл в котором хранятся переменные для которых доступ ограничен - секретные части. Пароли, конфиги и тд. Если их будет очень много, тогда нужно использовать сторонний сервис, который позволяет их хранить.

#7

Docker как среда выполнения. Docker - заранее подготовленный и упакованый образ системы, содержащий конкретные предустановленные приложения. Обычно заточены под запуск одной маленькой программы и узко специализирванны. Гарантирует что система будет в том состоянии в котором нам надо и мы сможем полностью этим управлять. В большинстве случаев существуют уже готовые образы.

#8

Ручные задачи(manual jobs). Могут применяться для одноразовых целей. Задачи которые сложно выполнять на клиентской машине (Например проблема со шрифтами. На разных ОС могут отличаться, тогда запускать систему в Docker). Могут быть осознаным тормозом, когда будет нужно ручное вмешательство.  
!!!!!!!!!!!   yml предлагает переиспользуемые секции  !!!!!!!!! 

#9

Подготовка сервера к работе. Это шаги которые необходимо сделать один раз вне дериктории проекта.
Для фронтенда особо не нужно настроек. Он генерирует билд и его нужно загрузить.
Дле бекенда нужно настроить БД, дамп, ноду и тд.
В последнее время для фронтенда предоставляют файл docker-compose - в нем содержимое того что нужно установить.
*CORS (Cross-Origin Resource Sharing, англ. «совместное использование ресурсов разных источников») — это стандарт, позволяющий предоставлять веб-страницам доступ к объектам сторонних интернет-ресурсов. Сторонним считается любой интернет-ресурс, который отличается от запрашиваемого протоколом, доменом или портом.
Для того, чтобы все хорошо работало - необходима продуманная документация. И чем раньше она будет, тем лучше.

#10

Процесс стандартного CD: 
git clone -> npm i -> eslint -> prettier -> build -> deploy to server 
Очень похожие процессы для бека и фронтенда 
Устанавливать node_modules или нет зависит от окружения и совпадают ли версии ноды в Runner и server.
Как запускать команду: ssh-userName@serverName comand
ssh deploy@myhost.ua pm2 restart app.js
не забывать на сервере в конце команды писать npm install --production для того, чтобы не устанавливать dev dependencies на сервер

Ключ хоста - средство с помощью которого можно убедиться что мы стучимся к нужному нам серверу и его никто не подменил.

Для работы с ssh необходимо несколько действий:
- создать отдельный файл где будет сохранен ssh 
- изменить права доступа к этому файлу
- ssh agent использовать этот сервис для получения идентификатора хоста 

Каждый инструмент установленный на сервере - потенциональный вектор атаки.

#11

Кеширование( имя и набор файлов - чаще всего такое определение)
Чтобы ПО работало быстрее, нужно оптимизировать. Когда оптимизация выполнена для еще большего ускорения нужно кешировать.
Например можно кешировать node_modules. Для кеширования необходим ключ кеширования.
В данном случае кеш - это какие элементы сохранить и по каким ключам использовать
Система должна работать стабильно как с кешами так и без. В ней могут быть настройки для кеширования, сколько они должны храниться, удаление и тд.
Рекомендовано кешировать не сами node_modules а дерикторию куда складываются пакеты ~/.npm
Кеш - фундаментальный инструмент ускорения pipline
Кеши невозможно пошарить между проектами
Оптимизировать кеширование - если что-то используется редко, например node_modules, может их тогда вынести отдельно в образ
Правило - предварительная оптимизация - зло!!!!!!!

#12 

Артефакты
Артефакты - это конечный результат труда который можно "пощупать". Например после митинга появляется список задач - где список задач и есть артефакт.
Артефакты живут ограниченное время - по умолчанию 7 дней. Они уникальны для конкретного pipline и не могут шариться между jobs. 
Резюме - их можно скачать, способ передачи данных между jobs и выдачи конкретного результата наружу, они всегда привязаны к конкректному pipline 

#13

Rewiev apps вручную
Игогда некоторые jobs могут проваливаться, но возможно для демонстрации клиенту нам будет необходимо что бы все равно был произведен деплой.
Миграции - изменения структуры базы данных. С их помощью можно проверить что БД не упадет
Действия - научиться разворачивать систему(БД, выбор свободного порта, иногда - научиться наполнять БД, производить очистку)
GDPR - производить для обезличивания БД перед заливкой при копировании(Безопасность).

#14 

Нюансы CI/CD в мире JS
Хороший вариант чтобы приложение находилось в монорепозитории. Он облегчает консистентность.
Для реализации хорошего CD необходимо следить за кодом - например, писать такой код, чтобы после выполнения миграций он не разрушался.
Это не просто изменения кода с последующей поддержкой програмистов.

#15

webpack & lazy load
Нужно продумывать обработчики ошибок для пользователя когда у нас обновляется приложение. Например - обновили фронтенд и может появится конфликт у старой версии фронтенда с бекендом. 

#16

CI-CD Безопасность
О безопасности лучше всего начинать говорить с самого начала проекта.
Для злоумышленика главной целью может быть ключ ssh.  С его помощью у него будет доступ к серверу, на котором он может разместить нелегальное прокси, использовать для майнинга или рассылки спама, для распространения вирусов, воровать пользовательские пароли и базу данных.
Проводить атаки могут через доступ к коду, когда кодовая база находится в одном месте с CI-CD. Для защиты есть возможность в платном варианте защитиь от изменения файл конфигурации.
Еще один вектор атаки - когда нет CD но при этом в Runner когда выполняются инструкции и туда можно вставить вредоносное ПО.
Еще вариант - когда много кода и у многих людей есть доступ к артефактам. Пример - в gitlab -> в дирректорию [.tmp] складывались отчеты в которых было гугловский доступ. 
Очевидно но стоит упомянуть - не указывать ключи в коде. Некоторые сервисы предупреждают об этом, а некоторые отзывают ключи. 
В npm пакетах есть post install scripts. Хакер может зарегистрировать такой же пакет и хотя билд после этого упадет, но в post install scripts можно врести вредоносные код. 
Задавать вопрос глядя на Pipline - а что здесь может пойти не так?
Задача не полностью избавится от уязвимостей, но не делать все слишком простым
Выдавать минимально необходимые вещи внутри Pipline на каждом шаге 

#17

Docker - инструмент изолированного окружения от которого ничего не зависит. 
Как его можно использовать? Например обновили версию приложения с 1.2 до 1.3 но при этом все поломалось. Чтобы максимально комфортно откатится к стабильной версии нужно создать контейнер с версией 1.2 в которой все ок и запустить его. Это называется - registry. Это облегчит шаг деплоя.
Есть еще и Npm registry
Zero down time deployment - когда у нас есть рабочая версия которая обслуживает трафик из интернета. Мы параллельно разворачиваем новую версию, и после того как она стала живой, переключаем со старой на новую версию, при этом старую уничтожаем. Или не уничтожаем старую, а переключаем на нее, если с новой что-то пошло не так -> blue - green deployment. 
Посмотреть про - Kubernetes, IaaC, Terraform, Prometheus, Grafana, Jaeger, Helm, Istio
Научиться деплоить с помощью Docker